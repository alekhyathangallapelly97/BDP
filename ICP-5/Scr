Task 1:
starting sql:
sudo service mysqld start
mysql -u root -pcloudera

creating and using a database:
create database db1;
use db1;

Creating a table named employee:
create table employee(emp_id int not null auto_increment, name varchar(100),salary int,primary key(emp_id));

Inserting values into the table:
insert into employee values(1,"mohit",200000),(2,"srujan",50000),(3,"mani",80000);

Displaying table contents:
select * from employee;

Importing table from mysql to hadoop using sqoop:
sqoop import --connect jdbc:mysql://localhost/db1 --username root --password cloudera  --table employee --m 1

Creating a new table named empnew to store data exported from hadoop:
create table empnew(emp_id int not null auto_increment, name varchar(100),salary int,primary key(emp_id));

Exporting data from hadoop to new table created in mysql:
sqoop export --connect jdbc:mysql://localhost/db1 --username root --password cloudera  --table empnew --export-dir employee/part-m-00000

Displaying table contents:
select * from empnew;




Task 2

Creating a table named emp in hive:
create table emp(emp_id int, name string) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile;

Loading data into it:
load data inpath 'employee/' into table emp;

Displaying data:
select * from emp;

Viewing whether the table is created or not:
hadoop fs -ls /user/hive/warehouse

Creating a table named emphive in sql:
create table emphive(emp_id int, name varchar(100));

Exporting data from hive to mysql:
sqoop export --connect jdbc:mysql://localhost/db1 --username root --password cloudera --table emphive --export-dir /user/hive/warehouse/emp -m 1

Displaying table contents:
select * from emphive;

Task 3
Creating a table named shakespeare in sql:
create table shakespeare(data varchar(100));

Loading the data present in all-shakespeare.txt in to table shakespeare:
load data local infile '/home/cloudera/Desktop/all-shakespeare.txt' into table shakespeare;

Importing data present in mysql table to hive table:
sqoop import --connect jdbc:mysql://localhost/db1 --username root --password cloudera  --table shakespeare --m 1 --hive-import --create-hive-table;

Applying Statistics query on shakespeare table (hive):
analyze table shakespeare compute statistics;

Applying Word count query on Shakespeare table(hive):
Select word,count(1) as count from( select explode(split(data,'//s')) as word from shakespeare) template group by word order by word;

Applying pattern query on shakespeare(hive):
Select * from tablename where data like '%ed.%' limit 10;
